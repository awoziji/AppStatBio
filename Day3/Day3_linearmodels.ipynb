{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 outline\n",
    "\n",
    "* Multiple linear regression\n",
    "    + Continuous and categorical predictors\n",
    "    + Interactions\n",
    "* Model formulae\n",
    "* Generalized Linear Models\n",
    "    + Linear, logistic, log-Linear links\n",
    "    + Poisson, Negative Binomial error distributions\n",
    "* Multiple Hypothesis Testing\n",
    "\n",
    "Textbook sources:\n",
    "\n",
    "* Chapter 5: Linear models\n",
    "* Chapter 6: Inference for high-dimensional data\n",
    "\n",
    "# Introduction to Linear Models\n",
    "\n",
    "## Example: friction of spider legs\n",
    "\n",
    "* Wolff & Gorb, [Radial arrangement of Janus-like setae permits friction control in spiders](http://www.nature.com/articles/srep01101), *Sci. Rep.* 2013.\n",
    "\n",
    "![spiderlegs](https://github.com/waldronlab/presentations/raw/master/Waldron_2018-06-06_EPIC/part%2003%20-%20Linear%20modeling/srep01101-f4.jpg)\n",
    "\n",
    "- **(A)** Barplot showing total claw tuft area of the corresponding legs. \n",
    "- **(B)** Boxplot presenting friction coefficient data illustrating median, interquartile range and extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Are the pulling and pushing friction coefficients different?\n",
    "- Are the friction coefficients different for the different leg pairs?\n",
    "- Does the difference between pulling and pushing friction coefficients vary by leg pair?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table(spider$leg,spider$type)\n",
    "summary(spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boxplot(spider$friction ~ spider$type * spider$leg,\n",
    "        col=c(\"grey90\",\"grey40\"), las=2,\n",
    "        main=\"Friction coefficients of different leg pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"columns-2\">\n",
    "\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Pulling friction is higher\n",
    "- Pulling (but not pushing) friction increases for further back legs (L1 -> 4)\n",
    "- Variance isn't constant\n",
    "\n",
    "</div>\n",
    "\n",
    "## What are linear models?\n",
    "\n",
    "The following are examples of linear models:\n",
    "\n",
    "1. $Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ (simple linear regression)\n",
    "2. $Y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i$ (quadratic regression)\n",
    "3. $Y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 \\times 2^{x_i} + \\varepsilon_i$ (2^{x_i} is a new transformed variable)\n",
    "\n",
    "## Multiple linear regression model\n",
    "\n",
    "- Linear models can have any number of predictors\n",
    "- Systematic part of model:\n",
    "\n",
    "$$\n",
    "E[y|x] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "- $E[y|x]$ is the expected value of $y$ given $x$\n",
    "- $y$ is the outcome, response, or dependent variable\n",
    "- $x$ is the vector of predictors / independent variables \n",
    "- $x_p$ are the individual predictors or independent variables\n",
    "- $\\beta_p$ are the regression coefficients\n",
    "\n",
    "\n",
    "Random part of model:\n",
    "\n",
    "$y_i = E[y_i|x_i] + \\epsilon_i$\n",
    "\n",
    "Assumptions of linear models: $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma_\\epsilon^2)$\n",
    "\n",
    "* Normal distribution\n",
    "* Mean zero at every value of predictors\n",
    "* Constant variance at every value of predictors\n",
    "* Values that are statistically independent\n",
    "\n",
    "## Continuous predictors\n",
    "\n",
    "* **Coding:** as-is, or may be scaled to unit variance (which results in _adjusted_ regression coefficients)\n",
    "* **Interpretation for linear regression:** An increase of one unit of the predictor results in this much difference in the continuous outcome variable\n",
    "\n",
    "## Binary predictors (2 levels)\n",
    "\n",
    "* **Coding:** indicator or dummy variable (0-1 coding)\n",
    "* **Interpretation for linear regression:** the increase or decrease in average outcome levels in the group coded “1”, compared to the reference category (“0”)\n",
    "   + _e.g._ $E(y|x) = \\beta_0 + \\beta_1 x$ \n",
    "   + where x={ 1 if push friction, 0 if pull friction }\n",
    "\n",
    "## Multilevel categorical predictors (ordinal or nominal)\n",
    "\n",
    "* **Coding:** $K-1$ dummy variables for $K$-level categorical variable\n",
    "* Comparisons with respect to a reference category, *e.g.* `L1`:\n",
    "    * `L2`={1 if $2^{nd}$ leg pair, 0 otherwise}, \n",
    "    * `L3`={1 if $3^{nd}$ leg pair, 0 otherwise}, \n",
    "    * `L4`={1 if $4^{th}$ leg pair, 0 otherwise}.\n",
    "\n",
    "- R re-codes factors to dummy variables automatically. \n",
    "- Dummy coding depends on whether factor is ordered or not.\n",
    "\n",
    "## Mini-exercise\n",
    "\n",
    "Using the `spider` object:\n",
    "1. Create a new variable `leg2` where `L1` / `L2` are merged, and `L3` / `L4` are merged\n",
    "2. Create a new variable `leg3` that is an \"ordered\" factor (see `?factor`)\n",
    "3. Make \"push\" the reference level for `spider$type` (see `?relevel`)\n",
    "\n",
    "# Model formulae in R\n",
    "\n",
    "[Model formulae tutorial](http://ww2.coastal.edu/kingw/statistics/R-tutorials/formulae.html)\n",
    "\n",
    "* regression functions in R such as `aov()`, `lm()`, `glm()`, and `coxph()` use a \"model formula\" interface.\n",
    "* The formula determines the model that will be built (and tested) by the R procedure. The basic format is:\n",
    "\n",
    "`> response variable ~ explanatory variables`\n",
    "\n",
    "* The tilde means \"is modeled by\" or \"is modeled as a function of.\" \n",
    "\n",
    "## Regression with a single predictor\n",
    "\n",
    "Model formula for simple linear regression: \n",
    "\n",
    "`> y ~ x`\n",
    "\n",
    "* where \"x\" is the explanatory (independent) variable\n",
    "* \"y\" is the response (dependent) variable. \n",
    "\n",
    "## Return to the spider legs\n",
    "\n",
    "Friction coefficient for leg type of first leg pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spider.sub <- spider[spider$leg==\"L1\", ]\n",
    "fit <- lm(friction ~ type, data=spider.sub)\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on spider leg type\n",
    "\n",
    "Regression coefficients for `friction ~ type` for first set of spider legs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.table <- xtable::xtable(fit, label=NULL)\n",
    "print(fit.table, type=\"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "* How to interpret this table?\n",
    "    * Coefficients for **(Intercept)** and **typepush**\n",
    "    * Coefficients are t-distributed when assumptions are correct\n",
    "    * Variance in the estimates of each coefficient can be calculated\n",
    "\n",
    "## Interpretation of spider leg type coefficients\n",
    "\n",
    "\n",
    "\n",
    "## regression on spider leg **position**\n",
    "\n",
    "Remember there are positions 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit <- lm(friction ~ leg, data=spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.table <- xtable::xtable(fit, label=NULL)\n",
    "print(fit.table, type=\"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interpretation of the dummy variables legL2, legL3, legL4 ?\n",
    "\n",
    "## Regression with multiple predictors\n",
    "\n",
    "Additional explanatory variables can be added as follows: \n",
    "\n",
    "`> y ~ x + z`\n",
    "\n",
    "Note that \"+\" does not have its usual meaning, which would be achieved by:\n",
    "\n",
    "`> y ~ I(x + z)`\n",
    "\n",
    "## Regression on spider leg **type** and **position**\n",
    "\n",
    "Remember there are positions 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit <- lm(friction ~ type + leg, data=spider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.table <- xtable::xtable(fit, label=NULL)\n",
    "print(fit.table, type=\"html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this model still doesn't represent how the friction differences between different leg positions are modified by whether it is pulling or pushing\n",
    "\n",
    "## Interaction (effect modification)\n",
    "\n",
    "Interaction is modeled as the product of two covariates:\n",
    "$$\n",
    "E[y|x] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1*x_2\n",
    "$$\n",
    "\n",
    "![Interaction between coffee and time of day on performance](coffee_interaction.jpg)\n",
    "  \n",
    "Image credit: http://personal.stevens.edu/~ysakamot/\n",
    "\n",
    "## Model formulae (cont'd)\n",
    "\n",
    "symbol  | example | meaning\n",
    "------- | ------------ | --------------------------  \n",
    "+ | + x\t| include this variable  \n",
    "-\t| - x\t| delete this variable  \n",
    ":\t| x : z\t| include the interaction  \n",
    "*\t| x * z\t| include these variables and their interactions  \n",
    "^\t| (u + v + w)^3\t| include these variables and all interactions up to three way\n",
    "1 | -1 | intercept: delete the intercept  \n",
    "\n",
    "Note: order generally doesn't matter (u+v OR v+u)\n",
    "\n",
    "## Summary: types of standard linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm( y ~ u + v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`u` and `v` factors: **ANOVA**  \n",
    "`u` and `v` numeric: **multiple regression**  \n",
    "one factor, one numeric: **ANCOVA**\n",
    "\n",
    "* R does a lot for you based on your variable classes\n",
    "    * be **sure** you know the classes of your variables\n",
    "    * be sure all rows of your regression output make sense\n",
    "\n",
    "## Mini-exercise\n",
    "\n",
    "Perform regression on the spider dataset to model friction as a function of type, leg, *and* the interaction of type and leg. Interpret the output of this regression.\n",
    "\n",
    "\n",
    "# Generalized Linear Models\n",
    "\n",
    "* Linear regression is a special case of a broad family of models called \"Generalized Linear Models\" (GLM)\n",
    "* This unifying approach allows to fit a large set of models using maximum likelihood estimation methods (MLE) (Nelder & Wedderburn, 1972)\n",
    "* Can model many types of data directly using appropriate distributions, e.g. Poisson distribution for count data\n",
    "* Transformations of $y$ not needed\n",
    "\n",
    "## Components of a GLM\n",
    "\n",
    "$$\n",
    "g\\left( E[y|x] \\right) = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    "$$\n",
    "\n",
    "* **Random component** specifies the conditional distribution for the response variable\n",
    "    + doesn’t have to be normal\n",
    "    + can be any distribution in the \"exponential\" family of distributions\n",
    "* **Systematic component** specifies linear function of predictors (linear predictor)\n",
    "* **Link** [denoted by g(.)] specifies the relationship between the expected value of the random component and the systematic component\n",
    "    + can be linear or nonlinear  \n",
    "\n",
    "## Linear Regression as GLM\n",
    "\n",
    "* Useful for log-transformed microarray data\n",
    "\n",
    "* **The model**: $y_i = E[y|x] + \\epsilon_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi} + \\epsilon_i$\n",
    "\n",
    "* **Random component** of $y_i$ is normally distributed:   $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma_\\epsilon^2)$\n",
    "\n",
    "* **Systematic component** (linear predictor): $\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}$\n",
    "\n",
    "* **Link function** here is the _identity link_: $g(E(y | x)) = E(y | x)$.  We are modeling the mean directly, no transformation.\n",
    "\n",
    "## Logistic Regression as GLM\n",
    "\n",
    "* Useful for binary outcomes, e.g. Single Nucleotide Polymorphisms or somatic variants\n",
    "\n",
    "* **The model**: \n",
    "$$\n",
    "Logit(P(x)) = log \\left( \\frac{P(x)}{1-P(x)} \\right) = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    "$$\n",
    "\n",
    "* **Random component**: $y_i$ follows a Binomial distribution (outcome is a binary variable)\n",
    "\n",
    "* **Systematic component**: linear predictor \n",
    "$$\n",
    "\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    "$$\n",
    "\n",
    "* **Link function**: _logit_ (log of the odds that the event occurs)\n",
    "\n",
    "$$\n",
    "g(P(x)) = logit(P(x)) = log\\left( \\frac{P(x)}{1-P(x)} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(x) = g^{-1}\\left( \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi}\n",
    " \\right)\n",
    "$$\n",
    "\n",
    "## Log-linear GLM\n",
    "\n",
    "The systematic part of the GLM is:\n",
    "\n",
    "$$\n",
    "log\\left( E[y|x] \\right) = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_p x_{pi} + log(t_i)\n",
    "$$\n",
    "\n",
    "* Common for count data\n",
    "    + can account for differences in sequencing depth by an *offset* $log(t_i)$\n",
    "    + guarantees non-negative expected number of counts\n",
    "    + often used in conjunction with Poisson or Negative Binomial error models\n",
    "    \n",
    "## Poisson error model\n",
    "\n",
    "$$\n",
    "f(k, \\lambda) = e^{-\\lambda} \\frac{\\lambda^k}{k!}\n",
    "$$\n",
    "\n",
    "* where $f$ is the probability of $k$ events (e.g. # of reads counted), and\n",
    "* $\\lambda$ is the mean number of events, so $E[y|x]$\n",
    "* $\\lambda$ is also the variance of the number of events\n",
    "\n",
    "## Negative Binomial error model\n",
    "\n",
    "* *aka* gamma–Poisson mixture distribution\n",
    "\n",
    "$$\n",
    "f(k, \\lambda, \\theta) = \\frac{\\Gamma(\\frac{1 + \\theta k}{\\theta})}{k! \\, \\Gamma(\\frac{1}{\\theta})} \n",
    "    \\left(\\frac{\\theta m}{1+\\theta m}\\right)^k \n",
    "    \\left(1+\\theta m\\right)^\\theta\n",
    "    \\quad\\text{for }k = 0, 1, 2, \\dotsc\n",
    "$$\n",
    "* where $f$ is still the probability of $k$ events (e.g. # of reads counted),\n",
    "* $\\lambda$ is still the mean number of events, so $E[y|x]$\n",
    "* An additional **dispersion parameter** $\\theta$ is estimated:\n",
    "    + $\\theta \\rightarrow 0$: Poisson distribution\n",
    "    + $\\theta \\rightarrow \\infty$: Gamma distribution    \n",
    "* The Poisson model can be considered as **nested** within the Negative Binomial model\n",
    "    + A likelihood ratio test comparing the two models is possible\n",
    "\n",
    "## Compare Poisson vs. Negative Binomial\n",
    "\n",
    "`dbinom()` Negative Binomial Distribution has two parameters: # of trials n, and probability of success p\n",
    "\n",
    "\n",
    "\n",
    "## Additive vs. multiplicative models\n",
    "\n",
    "* Linear regression is an _additive_ model\n",
    "    + _e.g._ for two binary variables $\\beta_1 = 1.5$, $\\beta_2 = 1.5$.\n",
    "    + If $x_1=1$ and $x_2=1$, this adds 3.0 to $E(y|x)$\n",
    "* Logistic and log-linear models are _multiplicative_:\n",
    "    + If $x_1=1$ and $x_2=1$, this adds 3.0 to $log(\\frac{P}{1-P})$\n",
    "    + Odds-ratio $\\frac{P}{1-P}$ increases 20-fold: $exp(1.5+1.5)$ or $exp(1.5) * exp(1.5)$\n",
    "\n",
    "# Inference in high dimensions (many variables)\n",
    "\n",
    "* Conceptually similar to what we have already done\n",
    "    * $Y_i$ expression of a gene, etc\n",
    "* Just repeated many times, e.g.:\n",
    "    * is the mean expression of a gene different between two groups (t-test)\n",
    "    * is the mean expression of a gene different between any of several groups (1-way ANOVA)\n",
    "    * do this simple analysis thousands of times\n",
    "    * *note*: for small sample sizes, some Bayesian improvements can be made (i.e. LIMMA package)\n",
    "* It is in prediction and machine learning where $Y$ is a label like patient outcome, and we can have high-dimensional predictors\n",
    "\n",
    "## Multiple testing\n",
    "\n",
    "* When testing thousands of true null hypotheses with $\\alpha = 0.05$, you expect a 5\\% type I error rate\n",
    "* What p-values are even smaller than you expect by chance from multiple testing?\n",
    "* Two mainstream approaches for controlling type I error rate:\n",
    "\n",
    "1. Family-wise error rate (*e.g.*, Bonferroni correction). \n",
    "    * Controlling FWER at 0.05 ensures that the probably of _any_ type I errors is < 0.05.\n",
    "2. False Discovery Rate (*e.g.*, Benjamini-Hochberg correction)\n",
    "    * Controlling FDR at 0.05 ensures that fraction of type I errors is < 0.05.\n",
    "    * correction for the smallest p-value is the same as the Bonferroni correction\n",
    "    * correction for larger p-values becomes less stringent\n",
    "\n",
    "## Mini-exercise\n",
    "\n",
    "Simulate the following vectors of p-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "p1 <- runif(1000)\n",
    "p2 <- c(runif(900), runif(100, min=0, max=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make histograms of these p-values. Does it look like there are more small p-values than expected if all null hypotheses are true?\n",
    "2. Use the `p.adjust` function to calculate Bonferroni-corrected (\"bonferroni\") p-values and Benjamini Hochberg False Discovery Rate (\"BH\"). For each of these simulations, how many p-values are < 0.05 for the raw, Bonferroni-adjusted, and BH-adjusted values?\n",
    "\n",
    "# Summary\n",
    "\n",
    "- Linear models are the basis for identifying differential expression / differential abundance\n",
    "    - anything with at least one continuous $X$ or $Y$\n",
    "- **Assumptions**: \n",
    "    1. normal, homoscadistic errors,\n",
    "    2. a linear relationship, and\n",
    "    3. independent observations.\n",
    "- Extends to binary $Y$ (logistic regression), count $Y$ (log-linear regression with e.g. Poisson or Negative Binomial link functions) through **Generalized Linear Models**\n",
    "\n",
    "- **Generalized Linear Models** extend linear regression to:\n",
    "    - binary $y$ (logistic regression)\n",
    "    - count $y$ (log-linear regression with e.g. Poisson or Negative Binomial link functions) \n",
    "- The basis for identifying differential expression / differential abundance\n",
    "\n",
    "\n",
    "# Exercises\n",
    "\n",
    "* [Design formula exercises](http://genomicsclass.github.io/book/pages/expressing_design_formula_exercises.html)\n",
    "* [Interactions and contrasts](http://genomicsclass.github.io/book/pages/interactions_and_contrasts_exercises.html) All **except 3**\n",
    "\n",
    "\n",
    "## Links\n",
    "\n",
    "- A built [html][] version of this lecture is available.\n",
    "- The [source][] R Markdown is also available from Github.\n",
    "\n",
    "[html]: http://rpubs.com/lwaldron/AppStatBio2019_day3\n",
    "[source]: https://github.com/waldronlab/AppStatBio\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
